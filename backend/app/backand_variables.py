# Remote Llama
from langchain_ollama.llms import OllamaLLM
llama_model = OllamaLLM(model="llama3.1")

# # Local Llama - not really
# from langchain_community.llms import Ollama
# llama_model = Ollama(model="mistral")
